{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Netflix dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_dataset_path = \"./../../Datasets/Netflix-prize-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_1_location = os.path.join(netflix_dataset_path, \"combined_data_1.txt\")\n",
    "combined_data_2_location = os.path.join(netflix_dataset_path, \"combined_data_2.txt\")\n",
    "combined_data_3_location = os.path.join(netflix_dataset_path, \"combined_data_3.txt\")\n",
    "combined_data_4_location = os.path.join(netflix_dataset_path, \"combined_data_4.txt\")\n",
    "\n",
    "help_location = f'{combined_data_1_location},{combined_data_2_location},{combined_data_3_location},{combined_data_4_location}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all data to the same sark context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = sc.textFile(help_location).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100498277 elements in the combined RDD\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {combined_data.count()} elements in the combined RDD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available data represent a movie id, followed by many reviews from different users. We wish to structure the data and group them by each individual user, since our target is to predict the rating that each user would assign to a movie. The following example shows that for the movied with id 1, the user with id 1488844 has rated it with 3 stars out of 5, with the rating date to be the 6th of Spetmeber, 2005. The next lines follow the same pattern, until all reviews are exhausted and then a single line with the number '2:' will show up, followed by the corresponding reviews for the second movie etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to efficiently perform the Alternating Least Squares algorith, we will need to re-map the form of these lines into the pattern 'user_id, movie_id, rating'. We do not care about the date of the ratings, since we do not intend to use them in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the dates of ratings from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dates(single_line):\n",
    "    \"\"\"\n",
    "    Removes the date of reviews. \n",
    "    \n",
    "    Inputs:\n",
    "        single line -> A single line of the original RDD, represented as a list fo strings.\n",
    "        \n",
    "    Outputs:\n",
    "        new_line -> A list of strings without the date. \n",
    "        \n",
    "    We need to take special care of the lines that represent a movie id, which only have a single element \n",
    "    in their list representation.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(single_line)==1:\n",
    "        return single_line\n",
    "    else:\n",
    "        return single_line[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dates_rdd = combined_data.map(lambda line: line.split(\",\")).map(lambda lst: remove_dates(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1:'],\n",
       " ['1488844', '3'],\n",
       " ['822109', '5'],\n",
       " ['885013', '4'],\n",
       " ['30878', '4'],\n",
       " ['823519', '3'],\n",
       " ['893988', '3'],\n",
       " ['124105', '4'],\n",
       " ['1248029', '3'],\n",
       " ['1842128', '4']]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_dates_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign a movie id to the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_and_assign(line, acc):\n",
    "    \n",
    "    if ':' in line[0]:\n",
    "        acc = line[0].split(\":\")[0]\n",
    "    else:\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
